retrieve_top_k: 10
rerank_top_k: 5
generation_top_k: 5
pyserini_num_threads: 4
run_name: null
dataset_folder: tests/dataset/test_bm25tiny/
index_folder: tests/index/test_bm25tiny/
runs_folder: tests/run/test_bm25tiny/
experiments_folder: tests/exp/test_bm25tiny
processing_num_proc: 40
overwrite_run: true
retriever:
  init_args:
    _target_: models.retrievers.bm25.BM25
    model_name: bm25
  batch_size: 1024
  batch_size_sim: 256
generator:
  init_args:
    _target_: models.generators.llm.LLM
    model_name: TinyLlama/TinyLlama-1.1B-Chat-v1.0
    max_new_tokens: 64
    max_length: 2048
    quantization: int4
  batch_size: 1
dataset:
  train:
    doc: null
    query: null
  dev:
    doc:
      init_args:
        _target_: modules.dataset_processor.UT1Docs
        split: fake
    query:
      init_args:
        _target_: modules.dataset_processor.UT1Queries
        split: faketest
  test:
    doc:
      init_args:
        _target_: modules.dataset_processor.UT1Docs
        split: fake
    query:
      init_args:
        _target_: modules.dataset_processor.UT1Queries
        split: faketest
prompt:
  system: You are a helpful assistant. Your task is to extract relevant information
    from provided documents and to answer to questions as short as possible.
  user: f"Background:\n{docs}\n\nQuestion:\ {question}"
  system_without_docs: You are a helpful assistant. Answer the questions as short
    as possible.
  user_without_docs: f"Question:\ {question}"
